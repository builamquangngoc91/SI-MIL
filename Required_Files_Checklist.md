# Required Files Checklist for PathExpert_feature_extraction.sh

## ✅ **Current Status - You Can Run The Script**

Your setup is **COMPLETE** and ready to run! You have all required files:

### Files You Already Have:

- ✅ **WSI Files**: `data_sample/slides/TCGA-A6-2686-01Z-00-DX1.0540a027-2a0c-46c7-9af0-7b8672631de7.svs`
- ✅ **HoVer-Net Output**: `data_sample/Hovernet_output/json/[WSI_NAME].json`
- ✅ **Train/Test Split**: `data_sample/train_test_dict.json`
- ✅ **Column Name Files**: All pickle files present
- ✅ **Python Scripts**: All extraction scripts present
- ✅ **Previous Results**: Feature extraction already completed

## 📋 **Complete Requirements List**

### **1. Input Data Files**

#### WSI Files (Required)

```
data_sample/slides/
└── [WSI_NAME].svs    # Whole Slide Image files
```

**Format**: `.svs`, `.tiff`, or other OpenSlide-compatible formats  
**Magnification**: Must have 40X magnification available  
**Status**: ✅ You have 1 WSI file

#### HoVer-Net Segmentation Results (Required)

```
data_sample/Hovernet_output/
├── json/
│   └── [WSI_NAME].json    # Cell segmentation and classification
└── mask/ (optional)
    └── [WSI_NAME].png     # Visualization masks
```

**Content**: JSON files containing cell coordinates, types, and properties  
**Generated by**: HoVer-Net model with PanNuke checkpoint  
**Status**: ✅ You have the required JSON files

#### Train/Test Split Definition (Required)

```
data_sample/train_test_dict.json
```

**Format**:

```json
{
  "train_dict": {
    "slide1.svs": 0, // 0=negative, 1=positive
    "slide2.svs": 1
  },
  "test_dict": {
    "slide3.svs": 0,
    "slide4.svs": 1
  }
}
```

**Status**: ✅ You have this file

#### Feature Column Name Files (Required)

```
data_sample/
├── athena_column_name.pickle      # ATHENA feature names
├── cell_stat_column_name.pickle   # Cell statistics feature names
└── sna_column_name.pickle         # Social network feature names
```

**Content**: Lists of feature column names for proper indexing  
**Status**: ✅ All files present

### **2. Processing Scripts (Required)**

All scripts must be in `data_curation/` directory:

- ✅ `extract_properties.py` - Cell morphology extraction
- ✅ `deepzoom_tiler_organ.py` - Patch extraction
- ✅ `patch_dict_list.py` - Patch indexing
- ✅ `extract_cell_statistics_features.py` - Cell statistics
- ✅ `extract_sna_features.py` - Social network analysis
- ✅ `extract_athena_spatial_features.py` - Spatial heterogeneity
- ✅ `extract_tissue_features.py` - Tissue features
- ✅ `club_features.py` - Feature combination
- ✅ `data_filtering.py` - Final processing

### **3. Directory Structure (Auto-created)**

The script will create these directories if they don't exist:

```
data_sample/
├── cell_property/          # Created by step 1
├── patches/               # Created by step 2
└── features/
    ├── cell_statistics/   # Created by step 4
    ├── sna_statistics/    # Created by step 5
    ├── athena_statistics/ # Created by step 6
    └── tissue_statistics/ # Created by step 7
```

## 🔧 **If Starting From Scratch**

### **Step 1: Prepare WSI Files**

1. Place all `.svs` files in `data_sample/slides/`
2. Ensure slides have 40X magnification available
3. Remove any slides without 40X magnification

### **Step 2: Run HoVer-Net Cell Segmentation**

Before running `PathExpert_feature_extraction.sh`, you need HoVer-Net results:

```bash
# Install HoVer-Net
git clone https://github.com/vqdang/hover_net.git
cd hover_net
conda env create -f environment.yml
conda activate hover_net

# Download PanNuke checkpoint
gdown --id 1SbSArI3KOOWHxRlxnjchO7_MbWzB4lNR

# Run HoVer-Net inference
parent_dir='/Users/nam.le/Desktop/research/SI-MIL/data_curation/data_sample'

python run_infer.py \
--gpu='0' \
--nr_types=6 \
--type_info_path=type_info.json \
--batch_size=100 \
--model_mode=fast \
--model_path=hovernet_fast_pannuke_type_tf2pytorch.tar \
--nr_inference_workers=6 \
--nr_post_proc_workers=6 \
wsi \
--input_dir="$parent_dir/slides" \
--proc_mag=40 \
--cache_path='cache' \
--output_dir="$parent_dir/Hovernet_output" \
--input_mask_dir="$parent_dir/Hovernet_output/msk" \
--chunk_shape=10000 \
--save_mask
```

### **Step 3: Create Train/Test Split**

Create `data_sample/train_test_dict.json`:

```json
{
  "train_dict": {
    "slide1.svs": 0,
    "slide2.svs": 1,
    "slide3.svs": 0
  },
  "test_dict": {
    "slide4.svs": 1,
    "slide5.svs": 0
  }
}
```

### **Step 4: Ensure Column Name Files**

Copy from `test_dataset/` or existing working directory:

- `athena_column_name.pickle`
- `cell_stat_column_name.pickle`
- `sna_column_name.pickle`

## 🚀 **Ready to Run**

Once you have all the above files, simply execute:

```bash
cd /Users/nam.le/Desktop/research/SI-MIL/data_curation
conda activate simil
chmod +x PathExpert_feature_extraction.sh
./PathExpert_feature_extraction.sh
```

## ⚠️ **Important Notes**

1. **Path Configuration**: Update the `parent_dir` path in `PathExpert_feature_extraction.sh` if needed
2. **Computational Resources**: Script uses 10 workers per step - adjust based on your system
3. **Storage Space**: Ensure sufficient disk space for patches and feature files
4. **Memory Requirements**: Large WSIs require substantial RAM (8GB+ recommended)
5. **Processing Time**: Can take several hours depending on WSI size and number

## 🔍 **Verification**

Your setup is ready when you have:

- [ ] WSI files in `slides/`
- [ ] HoVer-Net JSON files in `Hovernet_output/json/`
- [ ] Train/test split JSON file
- [ ] Column name pickle files
- [ ] All Python scripts present

**Your Current Status: ✅ ALL REQUIREMENTS MET**
